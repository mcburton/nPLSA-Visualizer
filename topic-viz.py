###############################
# topic-viz.py 
# A script for generating a static HTML site for analyzing the output of topic models generated by nPLSA
#
#
#
#
###############################

import os
import re
import sys
import json


dataDirectory = "./data/"
htmlDirectory = "./html/"



try:
	sizefilelist = [f for f in os.listdir(dataDirectory) if f.startswith('nplsa.topicSize.') and f[-1].isdigit()]
	iterations = max([int(re.sub("\D", "", f)) for f in sizefilelist])
	with open(dataDirectory + "nplsa.topicSize." + str(iterations)) as file:
   		numTopics = len(file.readlines())
except:
	print("""
There is something wrong with your data directory. 
It should contain a number of files named 'nplsa.topicsize.NUM'
Take a look in ./data and make sure the files are there.
		""")
	sys.exit()

print("Building data files for Topic Size visualization.")

series = [{"key":str(num), "values":[]} for num in range(0,numTopics)]  # set up the data structure for the d3.js visualization

# for filename in sizefilelist:
# 	num = int(re.sub("\D", "", filename))
# 	print(num)
# 	try:
# 		with open(dataDirectory + str(filename)) as file:
# 			content = [float(line.strip()) for line in file]
# 			line = content + ([0] * (numTopics - len(content)))
# 			for topic, value in enumerate(line):
# 				series[int(topic)]["values"].append({"x":num, "y":float(value)})
# 	except Exception, e:
# 		print(e)



for num in range(1,iterations):
	try:
		with open(dataDirectory + "nplsa.topicSize." + str(num)) as file:
			content = [float(line.strip()) for line in file]
			line = content + ([0] * (numTopics - len(content)))
			for topic, value in enumerate(line):
				series[int(topic)]["values"].append({"x":num, "y":float(value)})
	except Exception, e:
		print(e)


print("Writing topic size JSON files to HTML directory.")

with open(htmlDirectory+"meta.json", 'w') as metaJson:
	metaJson.write(json.dumps({"iterations":iterations, "numtopics":numTopics}))

with open(htmlDirectory+"topicSize.json",'w') as filey:
	filey.write(json.dumps(series))



###### PCA section
try:
	import numpy as np
	from sklearn import decomposition
except ImportError:
	print("You haven't installed scikit-learn. Please see the readme.md for details about installing the machine learning libraries.")
	sys.exit()


try:
		mapfilelist = [f for f in os.listdir(dataDirectory) if f.startswith('nplsa.model.') and f[-1].isdigit()]
except:
	print("You appear to be missing your nplsa.model files, I can't compute the topic plots without them.")


# topicGraphData = list()
# for filename in mapfilelist:
# 	step = int(re.sub("\D", "", filename))
# 	with open(dataDirectory + filename) as file:
# 		file.readline() # toss the first line of the file, it doesn't contain data
# 		data = [[float(num) for num in line.strip().split(" ")] for line in file]
# 		topicWords = np.array(data)
# 		pca = decomposition.PCA(n_components=2).fit(topicWords)
# 		points = pca.transform(topicWords)
# 		keyPoints = [{"key":"topic"+str(index), "point":point} for index, point in enumerate(points)]
# 	topicGraphData.append({"step":step, "points":keyPoints})


topicGraphData = list()

for filename in mapfilelist:
	step = int(re.sub("\D", "", filename))
	with open(dataDirectory + filename) as file:
		file.readline() # toss the first line of the file, it doesn't contain data
		data = [[float(num) for num in line.strip().split(" ")] for line in file]
		topicWords = np.array(data)
		pca = decomposition.PCA(n_components=2).fit(topicWords)
		points = pca.transform(topicWords)
		keyPoints = [{"key":"topic"+str(index), "point":point.tolist()} for index, point in enumerate(points)]
	topicGraphData.append({"step":step, "points":keyPoints})
    
topicGraphData = sorted(topicGraphData, key=lambda k: k['step'])


with open(htmlDirectory+"topicGraph.json",'w') as filey:
	filey.write(json.dumps(topicGraphData))

